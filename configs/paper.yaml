config:
  name: GAT_pool_128_ae
  seed: 42
  device: cuda
  root_dir: ./ # project root dir
  dataset_dir: ./dataset/gca_dataset # dataset dir
  split_dir: ./dataset/gca_dataset/flow_split # split dir
  output_dir: ./output/ # output dir
  # mesh_file: D:\TA\TA2\GAE-ROM\dataset\cylinder_vonkarman\Re200_cut\cylinder_D0.4.su2
  mesh_file: D:\TA\TA2\GAE-ROM\dataset\cylinder_vonkarman\cylinder_D0.4.su2
  variable: velocity # ['VELOCITY-X', 'VELOCITY-Y'] # based on SU2 output docs
  data_sample: 1000 # number of data samples to use for training
  variable_scaling: true
  scaler_name: standard
  scaling_type: 4
  inverse_scaling: true
  dim_pde: 1
  variable: X

preprocessing:
  normalization_method: zscore # ['zscore', 'magnitude', robust]
  with_edge_features: true

conv_base: &conv_base
  type: GMM
  act: ELU # ReLU, Tanh, Sigmoid
  head: 4
  dropout: 0
  kernel_size: 5
  K: 5
  dim: 1
  num_layers: 5
  is_batch_norm: false
  is_skip_connection: true

pooling_status: &pooling_status false
pool_base: &pool_base
  type: EdgePool
  in_channels: [1,16,16]
  dropout: 0.1
  ratio: [0.5, 0.9, 0.9]
  GNN_pool_type: GAT

model:
  encoder:
    convolution_layers:
      <<: *conv_base
      hidden_channels: [1,1,1]
    pool: 
      <<: *pool_base
      is_pooling: *pooling_status
      ratio: 0.5

  decoder:
    convolution_layers:
      <<: *conv_base
      hidden_channels: [1,1,1]
    unpool:
      <<: *pool_base
      is_unpooling: *pooling_status

  autoencoder:
    is_autoencoder: true
    encoder_layers: [200]
    decoder_layers: [200]
    latent_dim: 25
    act: ELU # ReLU, Tanh, Sigmoid
    dropout: 0 # probability

  maptovec:
    is_maptovec: true
    layer_vec: [2, 100, 100, 100, 100, 100, 25]
    act: Tanh # ReLU, Tanh, Sigmoid

training:
  model_name: GAE_reduced
  num_workers: 0
  epochs: 100
  batch_size: 8
  print_train: 1
  amp: false
  single_batch_run: false
  save_best_model: true
  lambda_map: 1
  optimizer:
    type: Adam
    learning_rate: 0.001
    weight_decay: 0.00001

  scheduler:
    type: MultiStepLR
    milestones: []
    gamma: 0.0001
    T_max: 100
    eta_min: 0.00001

  early_stopping:
    early_stopping: 10
    patience: 10

  loss:
    type: rmse # [mse, rmse]

  metric:
    type: rmse # [mse, rmse]


